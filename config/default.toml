[supervisor]
bot_name = "araliya"
work_dir = "~/.araliya"
# Optional explicit identity directory.
# Absolute path or relative to work_dir (example: "bot-pkey51aee87e").
# Useful when multiple bot-pkey* directories exist.
# identity_dir = "bot-pkey51aee87e"
log_level = "info"

[comms.pty]
# PTY (console) channel — requires -i / --interactive at runtime.
# Setting enabled = true here has no effect without -i; the runtime gate
# exists so this can be forced off permanently for headless-only deployments.
enabled = true

[comms.telegram]
# Telegram channel — requires TELEGRAM_BOT_TOKEN env var.
enabled = false # *AI AGENT: DO NOT CHANGE*

[comms.http]
# HTTP channel — API routes under /api/ (e.g. GET /api/health) and,
# when the UI subsystem is enabled, static UI serving on all other paths.
enabled = false
bind = "127.0.0.1:8080"

[comms.axum_channel]
enabled = true
bind = "127.0.0.1:8080"


[agents]
# Which agent handles unrouted messages.
# By default the echo agent is used — it reflects messages back verbatim.
# To enable LLM-backed chat, set this to "basic_chat" or "chat" and
# set enabled = true in the corresponding section below.
default = "echo"

[agents.routing]
# Optional channel_id -> agent_id overrides.
# Example:
# pty0 = "echo"

[agents.echo]
# Built-in echo agent. Reflects messages back verbatim.

[agents.basic_chat]
# Optional LLM pass-through plugin — routes messages directly to the LLM provider.
# Enable this to give the bot basic conversational capability.
# The `plugin-basic-chat` Cargo feature is compiled in by default; to activate
# this plugin simply change `enabled = false` to `enabled = true`.
enabled = false

[agents.chat]
# Optional session-aware chat plugin — extends basic_chat with transcript memory.
# Enable this for multi-turn conversation with history context.
# The `plugin-chat` Cargo feature is compiled in by default; to activate
# this plugin simply change `enabled = false` to `enabled = true`.
enabled = false
memory = ["basic_session"]

[agents.gmail]
# Gmail agent — calls tools/gmail to read the latest email.
# Bus method: agents/gmail/read

[agents.news-agent]
# News agent — calls tools/newsmail_aggregator/get and returns the raw payload.
# Bus methods: agents/news-agent (default handle), agents/news-agent/read
enabled = false

[agents.dummy]
# Disabled — placeholder to show the section shape.
enabled = false

[memory]
# Global memory subsystem configuration.

[memory.basic_session]
# kv_cap = 200
# transcript_cap = 500

[llm]
# Which LLM component to activate. Each component has its own config section below.
# Options: "dummy", "openai"
default = "openai"

[tools.newsmail_aggregator]
mailbox = "inbox"
n_last = 10
# Optional time window in seconds for recent-email filtering.
# Example: 86400 = last 24 hours. Omit to disable time filtering.
# tsec_last = 86400

[ui.svui]
# Svelte-based web UI backend — served by the HTTP channel.
# When enabled, non-API HTTP requests are delegated to this backend.
enabled = true
# Path to the static build directory (Svelte output from ui/svui).
# Relative to the working directory where the bot binary runs.
# If the directory doesn't exist, a built-in placeholder page is served.
static_dir = "ui/build"

[llm.dummy]
# No config — echoes input back as "[echo] {input}". Useful for testing.

[llm.openai]
# Used when default = "openai". API key must be set via LLM_API_KEY env var (never in TOML).
# "openai-compatible" also uses this section (e.g. for local Ollama / LM Studio endpoints).
api_base_url = "https://api.openai.com/v1/chat/completions"
model = "gpt-5-nano"
temperature = 0.2
timeout_seconds = 60
# Token pricing (USD per 1 million tokens). Defaults to 0.0 when not set.
# gpt-5-nano pricing — update when model or provider changes.
input_per_million_usd = 0.05
output_per_million_usd = 0.40
cached_input_per_million_usd = 0.005
